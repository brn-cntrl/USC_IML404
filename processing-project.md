# IML404 // Tangible + Spatial Computing // USC MA+P S19   

## Week 05. 02/04/2019 PROCESSING PROJECT DUE
use a RGB camera or a 3D sensor (the kinect) as an input device for your own art or design work.  you can also use a different input source or device provided it's been approved by one of the professors (eg audio, data). i'm imaging you'll build on the examples we worked with in class -- open cv, optical flow, agentâ€“based systems -- but feel free to explore other ways to interact with these sensors and discuss the options with us.

### THINGS YOU'LL SHOW + TURN IN:
- in-class demo
- your source code (zipped root folder with all assets)
- a txt document with your work's title and one or two sentences about the project 
- single representative photo / screen capture, ~1920x1080px. if your had many iterations of your project that you liked, you optionally can turn in a folder with multiple images.
- 30s to 2m video documentation... ~720p turned in or posted to vimeo/youtube/similar. feel free to use screen capture (quicktime player... new screen recording) and / or camera footage (e.g. a camera pointed at you and the computer / projection screen). this isn't about professional documentation and graphics (though feel free to add a title if you want), it's about showing someone interacting with your work via the camera / 3D sensor. keep in mind that most of the world will probably only see your work through documentation, so make it good! 